{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3aa2c1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "693fd31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "data = load_breast_cancer()\n",
    "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "y = pd.Series(data.target)\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb289f84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy for Original Dataset: 0.9736686849868033\n",
      "Mean Accuracy for Correlation-Reduced Dataset: 0.9754075454122031\n",
      "Mean Accuracy for PCA-Reduced Dataset: 0.9771774569166279\n",
      "Mean Accuracy for LDA-Reduced Dataset: 0.9684055270920664\n"
     ]
    }
   ],
   "source": [
    "# Define the Stratified K-Fold cross-validator\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize lists to store results\n",
    "accuracies_original = []\n",
    "accuracies_corr = []\n",
    "accuracies_pca = []\n",
    "accuracies_lda = []\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for train_index, test_index in kf.split(X, y):\n",
    "    # Split the data into training and testing sets for this fold\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    # Feature Reduction using Correlation Coefficient\n",
    "    corr_matrix = pd.DataFrame(X_train).corr().abs()\n",
    "    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "    to_drop = [column for column in upper.columns if any(upper[column] > 0.9)]\n",
    "    X_train_corr = pd.DataFrame(X_train).drop(columns=to_drop)\n",
    "    X_test_corr = pd.DataFrame(X_test).drop(columns=to_drop)\n",
    "\n",
    "    # Feature Reduction using PCA\n",
    "    pca = PCA(n_components=0.95)  # Preserve 95% of the variance\n",
    "    X_train_pca = pca.fit_transform(X_train)\n",
    "    X_test_pca = pca.transform(X_test)\n",
    "\n",
    "    # Feature Reduction using LDA\n",
    "    lda = LDA(n_components=1)  # LDA can have at most (number of classes - 1) components for binary classification\n",
    "    X_train_lda = lda.fit_transform(X_train, y_train)\n",
    "    X_test_lda = lda.transform(X_test)\n",
    "\n",
    "    # Train and Evaluate Logistic Regression Models\n",
    "\n",
    "    # Original Dataset\n",
    "    model_original = LogisticRegression(random_state=42)\n",
    "    model_original.fit(X_train, y_train)\n",
    "    y_pred_original = model_original.predict(X_test)\n",
    "    accuracies_original.append(accuracy_score(y_test, y_pred_original))\n",
    "\n",
    "    # Correlation-Reduced Dataset\n",
    "    model_corr = LogisticRegression(random_state=42)\n",
    "    model_corr.fit(X_train_corr, y_train)\n",
    "    y_pred_corr = model_corr.predict(X_test_corr)\n",
    "    accuracies_corr.append(accuracy_score(y_test, y_pred_corr))\n",
    "\n",
    "    # PCA-Reduced Dataset\n",
    "    model_pca = LogisticRegression(random_state=42)\n",
    "    model_pca.fit(X_train_pca, y_train)\n",
    "    y_pred_pca = model_pca.predict(X_test_pca)\n",
    "    accuracies_pca.append(accuracy_score(y_test, y_pred_pca))\n",
    "\n",
    "    # LDA-Reduced Dataset\n",
    "    model_lda = LogisticRegression(random_state=42)\n",
    "    model_lda.fit(X_train_lda, y_train)\n",
    "    y_pred_lda = model_lda.predict(X_test_lda)\n",
    "    accuracies_lda.append(accuracy_score(y_test, y_pred_lda))\n",
    "\n",
    "# Calculate the mean accuracy for each method across all folds\n",
    "print(\"Mean Accuracy for Original Dataset:\", np.mean(accuracies_original))\n",
    "print(\"Mean Accuracy for Correlation-Reduced Dataset:\", np.mean(accuracies_corr))\n",
    "print(\"Mean Accuracy for PCA-Reduced Dataset:\", np.mean(accuracies_pca))\n",
    "print(\"Mean Accuracy for LDA-Reduced Dataset:\", np.mean(accuracies_lda))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616d36e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da375f13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060439ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751cfb8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcdbc8b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7294982e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b95fcda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "data = load_breast_cancer()\n",
    "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "y = pd.Series(data.target)\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e3e6ba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy for Original Dataset: 0.9736686849868033\n",
      "Mean Precision for Original Dataset: 0.9682543479911901\n",
      "Mean Recall for Original Dataset: 0.9915884194053209\n",
      "Mean F1-Score for Original Dataset: 0.9794339645403476\n",
      "Confusion Matrix for Original Dataset:\n",
      " [[200  12]\n",
      " [  3 354]]\n",
      "\n",
      "Mean Accuracy for Correlation-Reduced Dataset: 0.9754075454122031\n",
      "Mean Precision for Correlation-Reduced Dataset: 0.9703665199364704\n",
      "Mean Recall for Correlation-Reduced Dataset: 0.9915884194053209\n",
      "Mean F1-Score for Correlation-Reduced Dataset: 0.9807047622856266\n",
      "Confusion Matrix for Correlation-Reduced Dataset:\n",
      " [[201  11]\n",
      " [  3 354]]\n",
      "\n",
      "Mean Accuracy for PCA-Reduced Dataset: 0.9771774569166279\n",
      "Mean Precision for PCA-Reduced Dataset: 0.9782569712569714\n",
      "Mean Recall for PCA-Reduced Dataset: 0.9860328638497652\n",
      "Mean F1-Score for PCA-Reduced Dataset: 0.9818711966159823\n",
      "Confusion Matrix for PCA-Reduced Dataset:\n",
      " [[204   8]\n",
      " [  5 352]]\n",
      "\n",
      "Mean Accuracy for LDA-Reduced Dataset: 0.9684055270920664\n",
      "Mean Precision for LDA-Reduced Dataset: 0.9603104841435923\n",
      "Mean Recall for LDA-Reduced Dataset: 0.9916275430359939\n",
      "Mean F1-Score for LDA-Reduced Dataset: 0.9755004474370039\n",
      "Confusion Matrix for LDA-Reduced Dataset:\n",
      " [[197  15]\n",
      " [  3 354]]\n"
     ]
    }
   ],
   "source": [
    "# Define the Stratified K-Fold cross-validator\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize lists to store results\n",
    "accuracies_original = []\n",
    "precisions_original = []\n",
    "recalls_original = []\n",
    "f1s_original = []\n",
    "confusion_matrices_original = []\n",
    "\n",
    "accuracies_corr = []\n",
    "precisions_corr = []\n",
    "recalls_corr = []\n",
    "f1s_corr = []\n",
    "confusion_matrices_corr = []\n",
    "\n",
    "accuracies_pca = []\n",
    "precisions_pca = []\n",
    "recalls_pca = []\n",
    "f1s_pca = []\n",
    "confusion_matrices_pca = []\n",
    "\n",
    "accuracies_lda = []\n",
    "precisions_lda = []\n",
    "recalls_lda = []\n",
    "f1s_lda = []\n",
    "confusion_matrices_lda = []\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for train_index, test_index in kf.split(X, y):\n",
    "    # Split the data into training and testing sets for this fold\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    # Feature Reduction using Correlation Coefficient\n",
    "    corr_matrix = pd.DataFrame(X_train).corr().abs()\n",
    "    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "    to_drop = [column for column in upper.columns if any(upper[column] > 0.9)]\n",
    "    X_train_corr = pd.DataFrame(X_train).drop(columns=to_drop)\n",
    "    X_test_corr = pd.DataFrame(X_test).drop(columns=to_drop)\n",
    "\n",
    "    # Feature Reduction using PCA\n",
    "    pca = PCA(n_components=0.95)  # Preserve 95% of the variance\n",
    "    X_train_pca = pca.fit_transform(X_train)\n",
    "    X_test_pca = pca.transform(X_test)\n",
    "\n",
    "    # Feature Reduction using LDA\n",
    "    lda = LDA(n_components=1)  # LDA can have at most (number of classes - 1) components for binary classification\n",
    "    X_train_lda = lda.fit_transform(X_train, y_train)\n",
    "    X_test_lda = lda.transform(X_test)\n",
    "\n",
    "    # Train and Evaluate Logistic Regression Models\n",
    "\n",
    "    # Original Dataset\n",
    "    model_original = LogisticRegression(random_state=42)\n",
    "    model_original.fit(X_train, y_train)\n",
    "    y_pred_original = model_original.predict(X_test)\n",
    "    accuracies_original.append(accuracy_score(y_test, y_pred_original))\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_pred_original, average='binary')\n",
    "    precisions_original.append(precision)\n",
    "    recalls_original.append(recall)\n",
    "    f1s_original.append(f1)\n",
    "    confusion_matrices_original.append(confusion_matrix(y_test, y_pred_original))\n",
    "\n",
    "    # Correlation-Reduced Dataset\n",
    "    model_corr = LogisticRegression(random_state=42)\n",
    "    model_corr.fit(X_train_corr, y_train)\n",
    "    y_pred_corr = model_corr.predict(X_test_corr)\n",
    "    accuracies_corr.append(accuracy_score(y_test, y_pred_corr))\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_pred_corr, average='binary')\n",
    "    precisions_corr.append(precision)\n",
    "    recalls_corr.append(recall)\n",
    "    f1s_corr.append(f1)\n",
    "    confusion_matrices_corr.append(confusion_matrix(y_test, y_pred_corr))\n",
    "\n",
    "    # PCA-Reduced Dataset\n",
    "    model_pca = LogisticRegression(random_state=42)\n",
    "    model_pca.fit(X_train_pca, y_train)\n",
    "    y_pred_pca = model_pca.predict(X_test_pca)\n",
    "    accuracies_pca.append(accuracy_score(y_test, y_pred_pca))\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_pred_pca, average='binary')\n",
    "    precisions_pca.append(precision)\n",
    "    recalls_pca.append(recall)\n",
    "    f1s_pca.append(f1)\n",
    "    confusion_matrices_pca.append(confusion_matrix(y_test, y_pred_pca))\n",
    "\n",
    "    # LDA-Reduced Dataset\n",
    "    model_lda = LogisticRegression(random_state=42)\n",
    "    model_lda.fit(X_train_lda, y_train)\n",
    "    y_pred_lda = model_lda.predict(X_test_lda)\n",
    "    accuracies_lda.append(accuracy_score(y_test, y_pred_lda))\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_pred_lda, average='binary')\n",
    "    precisions_lda.append(precision)\n",
    "    recalls_lda.append(recall)\n",
    "    f1s_lda.append(f1)\n",
    "    confusion_matrices_lda.append(confusion_matrix(y_test, y_pred_lda))\n",
    "\n",
    "# Calculate mean performance metrics across all folds\n",
    "print(\"Mean Accuracy for Original Dataset:\", np.mean(accuracies_original))\n",
    "print(\"Mean Precision for Original Dataset:\", np.mean(precisions_original))\n",
    "print(\"Mean Recall for Original Dataset:\", np.mean(recalls_original))\n",
    "print(\"Mean F1-Score for Original Dataset:\", np.mean(f1s_original))\n",
    "print(\"Confusion Matrix for Original Dataset:\\n\", np.sum(confusion_matrices_original, axis=0))\n",
    "\n",
    "print(\"\\nMean Accuracy for Correlation-Reduced Dataset:\", np.mean(accuracies_corr))\n",
    "print(\"Mean Precision for Correlation-Reduced Dataset:\", np.mean(precisions_corr))\n",
    "print(\"Mean Recall for Correlation-Reduced Dataset:\", np.mean(recalls_corr))\n",
    "print(\"Mean F1-Score for Correlation-Reduced Dataset:\", np.mean(f1s_corr))\n",
    "print(\"Confusion Matrix for Correlation-Reduced Dataset:\\n\", np.sum(confusion_matrices_corr, axis=0))\n",
    "\n",
    "print(\"\\nMean Accuracy for PCA-Reduced Dataset:\", np.mean(accuracies_pca))\n",
    "print(\"Mean Precision for PCA-Reduced Dataset:\", np.mean(precisions_pca))\n",
    "print(\"Mean Recall for PCA-Reduced Dataset:\", np.mean(recalls_pca))\n",
    "print(\"Mean F1-Score for PCA-Reduced Dataset:\", np.mean(f1s_pca))\n",
    "print(\"Confusion Matrix for PCA-Reduced Dataset:\\n\", np.sum(confusion_matrices_pca, axis=0))\n",
    "\n",
    "print(\"\\nMean Accuracy for LDA-Reduced Dataset:\", np.mean(accuracies_lda))\n",
    "print(\"Mean Precision for LDA-Reduced Dataset:\", np.mean(precisions_lda))\n",
    "print(\"Mean Recall for LDA-Reduced Dataset:\", np.mean(recalls_lda))\n",
    "print(\"Mean F1-Score for LDA-Reduced Dataset:\", np.mean(f1s_lda))\n",
    "print(\"Confusion Matrix for LDA-Reduced Dataset:\\n\", np.sum(confusion_matrices_lda, axis=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143bed66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c40ce4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b001ec8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4514bd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4a05a88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original number of features: 30\n",
      "Number of features after correlation reduction: 20\n",
      "Number of features after PCA reduction: 10\n",
      "Number of features after LDA reduction: 1\n",
      "Original number of features: 30\n",
      "Number of features after correlation reduction: 19\n",
      "Number of features after PCA reduction: 10\n",
      "Number of features after LDA reduction: 1\n",
      "Original number of features: 30\n",
      "Number of features after correlation reduction: 20\n",
      "Number of features after PCA reduction: 10\n",
      "Number of features after LDA reduction: 1\n",
      "Original number of features: 30\n",
      "Number of features after correlation reduction: 20\n",
      "Number of features after PCA reduction: 10\n",
      "Number of features after LDA reduction: 1\n",
      "Original number of features: 30\n",
      "Number of features after correlation reduction: 20\n",
      "Number of features after PCA reduction: 10\n",
      "Number of features after LDA reduction: 1\n",
      "\n",
      "Mean Accuracy for Original Dataset: 0.9736686849868033\n",
      "Mean Precision for Original Dataset: 0.9682543479911901\n",
      "Mean Recall for Original Dataset: 0.9915884194053209\n",
      "Mean F1-Score for Original Dataset: 0.9794339645403476\n",
      "Confusion Matrix for Original Dataset:\n",
      " [[200  12]\n",
      " [  3 354]]\n",
      "\n",
      "Mean Accuracy for Correlation-Reduced Dataset: 0.9754075454122031\n",
      "Mean Precision for Correlation-Reduced Dataset: 0.9703665199364704\n",
      "Mean Recall for Correlation-Reduced Dataset: 0.9915884194053209\n",
      "Mean F1-Score for Correlation-Reduced Dataset: 0.9807047622856269\n",
      "Confusion Matrix for Correlation-Reduced Dataset:\n",
      " [[201  11]\n",
      " [  3 354]]\n",
      "\n",
      "Mean Accuracy for PCA-Reduced Dataset: 0.9771774569166279\n",
      "Mean Precision for PCA-Reduced Dataset: 0.9782569712569714\n",
      "Mean Recall for PCA-Reduced Dataset: 0.9860328638497652\n",
      "Mean F1-Score for PCA-Reduced Dataset: 0.9818711966159823\n",
      "Confusion Matrix for PCA-Reduced Dataset:\n",
      " [[204   8]\n",
      " [  5 352]]\n",
      "\n",
      "Mean Accuracy for LDA-Reduced Dataset: 0.9684055270920664\n",
      "Mean Precision for LDA-Reduced Dataset: 0.9603104841435923\n",
      "Mean Recall for LDA-Reduced Dataset: 0.9916275430359939\n",
      "Mean F1-Score for LDA-Reduced Dataset: 0.9755004474370039\n",
      "Confusion Matrix for LDA-Reduced Dataset:\n",
      " [[197  15]\n",
      " [  3 354]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the dataset\n",
    "data = load_breast_cancer()\n",
    "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "y = pd.Series(data.target)\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Define the Stratified K-Fold cross-validator\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize lists to store results\n",
    "accuracies_original = []\n",
    "precisions_original = []\n",
    "recalls_original = []\n",
    "f1s_original = []\n",
    "confusion_matrices_original = []\n",
    "\n",
    "accuracies_corr = []\n",
    "precisions_corr = []\n",
    "recalls_corr = []\n",
    "f1s_corr = []\n",
    "confusion_matrices_corr = []\n",
    "\n",
    "accuracies_pca = []\n",
    "precisions_pca = []\n",
    "recalls_pca = []\n",
    "f1s_pca = []\n",
    "confusion_matrices_pca = []\n",
    "\n",
    "accuracies_lda = []\n",
    "precisions_lda = []\n",
    "recalls_lda = []\n",
    "f1s_lda = []\n",
    "confusion_matrices_lda = []\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for train_index, test_index in kf.split(X, y):\n",
    "    # Split the data into training and testing sets for this fold\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    # Feature Reduction using Correlation Coefficient\n",
    "    corr_matrix = pd.DataFrame(X_train).corr().abs()\n",
    "    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "    to_drop = [column for column in upper.columns if any(upper[column] > 0.9)]\n",
    "    X_train_corr = pd.DataFrame(X_train).drop(columns=to_drop)\n",
    "    X_test_corr = pd.DataFrame(X_test).drop(columns=to_drop)\n",
    "\n",
    "    # Print the number of features before and after correlation-based reduction\n",
    "    print(f\"Original number of features: {X_train.shape[1]}\")\n",
    "    print(f\"Number of features after correlation reduction: {X_train_corr.shape[1]}\")\n",
    "\n",
    "    # Feature Reduction using PCA\n",
    "    pca = PCA(n_components=0.95)  # Preserve 95% of the variance\n",
    "    X_train_pca = pca.fit_transform(X_train)\n",
    "    X_test_pca = pca.transform(X_test)\n",
    "\n",
    "    # Print the number of features after PCA reduction\n",
    "    print(f\"Number of features after PCA reduction: {X_train_pca.shape[1]}\")\n",
    "\n",
    "    # Feature Reduction using LDA\n",
    "    lda = LDA(n_components=1)  # LDA can have at most (number of classes - 1) components for binary classification\n",
    "    X_train_lda = lda.fit_transform(X_train, y_train)\n",
    "    X_test_lda = lda.transform(X_test)\n",
    "\n",
    "    # Print the number of features after LDA reduction\n",
    "    print(f\"Number of features after LDA reduction: {X_train_lda.shape[1]}\")\n",
    "\n",
    "    # Train and Evaluate Logistic Regression Models\n",
    "\n",
    "    # Original Dataset\n",
    "    model_original = LogisticRegression(random_state=42)\n",
    "    model_original.fit(X_train, y_train)\n",
    "    y_pred_original = model_original.predict(X_test)\n",
    "    accuracies_original.append(accuracy_score(y_test, y_pred_original))\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_pred_original, average='binary')\n",
    "    precisions_original.append(precision)\n",
    "    recalls_original.append(recall)\n",
    "    f1s_original.append(f1)\n",
    "    confusion_matrices_original.append(confusion_matrix(y_test, y_pred_original))\n",
    "\n",
    "    # Correlation-Reduced Dataset\n",
    "    model_corr = LogisticRegression(random_state=42)\n",
    "    model_corr.fit(X_train_corr, y_train)\n",
    "    y_pred_corr = model_corr.predict(X_test_corr)\n",
    "    accuracies_corr.append(accuracy_score(y_test, y_pred_corr))\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_pred_corr, average='binary')\n",
    "    precisions_corr.append(precision)\n",
    "    recalls_corr.append(recall)\n",
    "    f1s_corr.append(f1)\n",
    "    confusion_matrices_corr.append(confusion_matrix(y_test, y_pred_corr))\n",
    "\n",
    "    # PCA-Reduced Dataset\n",
    "    model_pca = LogisticRegression(random_state=42)\n",
    "    model_pca.fit(X_train_pca, y_train)\n",
    "    y_pred_pca = model_pca.predict(X_test_pca)\n",
    "    accuracies_pca.append(accuracy_score(y_test, y_pred_pca))\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_pred_pca, average='binary')\n",
    "    precisions_pca.append(precision)\n",
    "    recalls_pca.append(recall)\n",
    "    f1s_pca.append(f1)\n",
    "    confusion_matrices_pca.append(confusion_matrix(y_test, y_pred_pca))\n",
    "\n",
    "    # LDA-Reduced Dataset\n",
    "    model_lda = LogisticRegression(random_state=42)\n",
    "    model_lda.fit(X_train_lda, y_train)\n",
    "    y_pred_lda = model_lda.predict(X_test_lda)\n",
    "    accuracies_lda.append(accuracy_score(y_test, y_pred_lda))\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_pred_lda, average='binary')\n",
    "    precisions_lda.append(precision)\n",
    "    recalls_lda.append(recall)\n",
    "    f1s_lda.append(f1)\n",
    "    confusion_matrices_lda.append(confusion_matrix(y_test, y_pred_lda))\n",
    "\n",
    "# Calculate mean performance metrics across all folds\n",
    "print(\"\\nMean Accuracy for Original Dataset:\", np.mean(accuracies_original))\n",
    "print(\"Mean Precision for Original Dataset:\", np.mean(precisions_original))\n",
    "print(\"Mean Recall for Original Dataset:\", np.mean(recalls_original))\n",
    "print(\"Mean F1-Score for Original Dataset:\", np.mean(f1s_original))\n",
    "print(\"Confusion Matrix for Original Dataset:\\n\", np.sum(confusion_matrices_original, axis=0))\n",
    "\n",
    "print(\"\\nMean Accuracy for Correlation-Reduced Dataset:\", np.mean(accuracies_corr))\n",
    "print(\"Mean Precision for Correlation-Reduced Dataset:\", np.mean(precisions_corr))\n",
    "print(\"Mean Recall for Correlation-Reduced Dataset:\", np.mean(recalls_corr))\n",
    "print(\"Mean F1-Score for Correlation-Reduced Dataset:\", np.mean(f1s_corr))\n",
    "print(\"Confusion Matrix for Correlation-Reduced Dataset:\\n\", np.sum(confusion_matrices_corr, axis=0))\n",
    "\n",
    "print(\"\\nMean Accuracy for PCA-Reduced Dataset:\", np.mean(accuracies_pca))\n",
    "print(\"Mean Precision for PCA-Reduced Dataset:\", np.mean(precisions_pca))\n",
    "print(\"Mean Recall for PCA-Reduced Dataset:\", np.mean(recalls_pca))\n",
    "print(\"Mean F1-Score for PCA-Reduced Dataset:\", np.mean(f1s_pca))\n",
    "print(\"Confusion Matrix for PCA-Reduced Dataset:\\n\", np.sum(confusion_matrices_pca, axis=0))\n",
    "\n",
    "print(\"\\nMean Accuracy for LDA-Reduced Dataset:\", np.mean(accuracies_lda))\n",
    "print(\"Mean Precision for LDA-Reduced Dataset:\", np.mean(precisions_lda))\n",
    "print(\"Mean Recall for LDA-Reduced Dataset:\", np.mean(recalls_lda))\n",
    "print(\"Mean F1-Score for LDA-Reduced Dataset:\", np.mean(f1s_lda))\n",
    "print(\"Confusion Matrix for LDA-Reduced Dataset:\\n\", np.sum(confusion_matrices_lda, axis=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b73d48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
